{
  "cells": [
    {
      "cell_type": "code",
      "execution_count": 1,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "5XpkzpoxIG_R",
        "outputId": "2dce9f30-4dc8-4ecf-e76c-6c6cb4e21daa"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Mounted at /content/drive\n",
            "/content/drive/MyDrive\n",
            "/content/drive/MyDrive/11868\n",
            "fatal: destination path 'llmsys_code_examples' already exists and is not an empty directory.\n",
            "/content/drive/MyDrive/11868/llmsys_code_examples/tensor_demo/miniTorch\n"
          ]
        }
      ],
      "source": [
        "from google.colab import drive\n",
        "drive.mount('/content/drive')\n",
        "%cd /content/drive/MyDrive/\n",
        "!mkdir -p 11868\n",
        "%cd /content/drive/MyDrive/11868\n",
        "!git clone https://github.com/llmsystem/llmsys_code_examples.git\n",
        "%cd /content/drive/MyDrive/11868/llmsys_code_examples/tensor_demo/miniTorch"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "gH9OYx-XJNGQ"
      },
      "source": [
        "## MiniTorch Installation"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 2,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "X19up_KxJG3y",
        "outputId": "67dd67ed-dfd7-41d3-b079-998dda69b1d7"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Collecting colorama==0.4.3 (from -r requirements.txt (line 1))\n",
            "  Downloading colorama-0.4.3-py2.py3-none-any.whl (15 kB)\n",
            "Collecting hypothesis==6.54 (from -r requirements.txt (line 2))\n",
            "  Downloading hypothesis-6.54.0-py3-none-any.whl (389 kB)\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m389.6/389.6 kB\u001b[0m \u001b[31m6.2 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hCollecting mypy==0.971 (from -r requirements.txt (line 3))\n",
            "  Downloading mypy-0.971-cp310-cp310-manylinux_2_5_x86_64.manylinux1_x86_64.manylinux_2_12_x86_64.manylinux2010_x86_64.whl (17.6 MB)\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m17.6/17.6 MB\u001b[0m \u001b[31m77.2 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hRequirement already satisfied: numba==0.58.1 in /usr/local/lib/python3.10/dist-packages (from -r requirements.txt (line 4)) (0.58.1)\n",
            "Requirement already satisfied: numpy==1.23.5 in /usr/local/lib/python3.10/dist-packages (from -r requirements.txt (line 5)) (1.23.5)\n",
            "Collecting pre-commit==2.20.0 (from -r requirements.txt (line 6))\n",
            "  Downloading pre_commit-2.20.0-py2.py3-none-any.whl (199 kB)\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m199.5/199.5 kB\u001b[0m \u001b[31m32.2 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hCollecting pytest==7.1.2 (from -r requirements.txt (line 7))\n",
            "  Downloading pytest-7.1.2-py3-none-any.whl (297 kB)\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m297.0/297.0 kB\u001b[0m \u001b[31m39.4 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hCollecting pytest-env (from -r requirements.txt (line 8))\n",
            "  Downloading pytest_env-1.1.3-py3-none-any.whl (6.2 kB)\n",
            "Collecting pytest-runner==5.2 (from -r requirements.txt (line 9))\n",
            "  Downloading pytest_runner-5.2-py2.py3-none-any.whl (6.8 kB)\n",
            "Requirement already satisfied: typing_extensions in /usr/local/lib/python3.10/dist-packages (from -r requirements.txt (line 10)) (4.5.0)\n",
            "Requirement already satisfied: attrs>=19.2.0 in /usr/local/lib/python3.10/dist-packages (from hypothesis==6.54->-r requirements.txt (line 2)) (23.2.0)\n",
            "Requirement already satisfied: sortedcontainers<3.0.0,>=2.1.0 in /usr/local/lib/python3.10/dist-packages (from hypothesis==6.54->-r requirements.txt (line 2)) (2.4.0)\n",
            "Requirement already satisfied: exceptiongroup>=1.0.0rc8 in /usr/local/lib/python3.10/dist-packages (from hypothesis==6.54->-r requirements.txt (line 2)) (1.2.0)\n",
            "Collecting mypy-extensions>=0.4.3 (from mypy==0.971->-r requirements.txt (line 3))\n",
            "  Downloading mypy_extensions-1.0.0-py3-none-any.whl (4.7 kB)\n",
            "Requirement already satisfied: tomli>=1.1.0 in /usr/local/lib/python3.10/dist-packages (from mypy==0.971->-r requirements.txt (line 3)) (2.0.1)\n",
            "Requirement already satisfied: llvmlite<0.42,>=0.41.0dev0 in /usr/local/lib/python3.10/dist-packages (from numba==0.58.1->-r requirements.txt (line 4)) (0.41.1)\n",
            "Collecting cfgv>=2.0.0 (from pre-commit==2.20.0->-r requirements.txt (line 6))\n",
            "  Downloading cfgv-3.4.0-py2.py3-none-any.whl (7.2 kB)\n",
            "Collecting identify>=1.0.0 (from pre-commit==2.20.0->-r requirements.txt (line 6))\n",
            "  Downloading identify-2.5.33-py2.py3-none-any.whl (98 kB)\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m98.9/98.9 kB\u001b[0m \u001b[31m17.0 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hCollecting nodeenv>=0.11.1 (from pre-commit==2.20.0->-r requirements.txt (line 6))\n",
            "  Downloading nodeenv-1.8.0-py2.py3-none-any.whl (22 kB)\n",
            "Requirement already satisfied: pyyaml>=5.1 in /usr/local/lib/python3.10/dist-packages (from pre-commit==2.20.0->-r requirements.txt (line 6)) (6.0.1)\n",
            "Requirement already satisfied: toml in /usr/local/lib/python3.10/dist-packages (from pre-commit==2.20.0->-r requirements.txt (line 6)) (0.10.2)\n",
            "Collecting virtualenv>=20.0.8 (from pre-commit==2.20.0->-r requirements.txt (line 6))\n",
            "  Downloading virtualenv-20.25.0-py3-none-any.whl (3.8 MB)\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m3.8/3.8 MB\u001b[0m \u001b[31m96.4 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hRequirement already satisfied: iniconfig in /usr/local/lib/python3.10/dist-packages (from pytest==7.1.2->-r requirements.txt (line 7)) (2.0.0)\n",
            "Requirement already satisfied: packaging in /usr/local/lib/python3.10/dist-packages (from pytest==7.1.2->-r requirements.txt (line 7)) (23.2)\n",
            "Requirement already satisfied: pluggy<2.0,>=0.12 in /usr/local/lib/python3.10/dist-packages (from pytest==7.1.2->-r requirements.txt (line 7)) (1.3.0)\n",
            "Collecting py>=1.8.2 (from pytest==7.1.2->-r requirements.txt (line 7))\n",
            "  Downloading py-1.11.0-py2.py3-none-any.whl (98 kB)\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m98.7/98.7 kB\u001b[0m \u001b[31m17.5 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hINFO: pip is looking at multiple versions of pytest-env to determine which version is compatible with other requirements. This could take a while.\n",
            "Collecting pytest-env (from -r requirements.txt (line 8))\n",
            "  Downloading pytest_env-1.1.2-py3-none-any.whl (6.2 kB)\n",
            "  Downloading pytest_env-1.1.1-py3-none-any.whl (6.2 kB)\n",
            "  Downloading pytest_env-1.1.0-py3-none-any.whl (6.2 kB)\n",
            "  Downloading pytest_env-1.0.1-py3-none-any.whl (5.3 kB)\n",
            "  Downloading pytest_env-1.0.0-py3-none-any.whl (5.3 kB)\n",
            "  Downloading pytest_env-0.8.2-py3-none-any.whl (5.3 kB)\n",
            "  Downloading pytest_env-0.8.1-py3-none-any.whl (5.2 kB)\n",
            "INFO: pip is looking at multiple versions of pytest-env to determine which version is compatible with other requirements. This could take a while.\n",
            "  Downloading pytest_env-0.8.0-py3-none-any.whl (5.2 kB)\n",
            "  Downloading pytest_env-0.7.0-py3-none-any.whl (4.9 kB)\n",
            "  Downloading pytest-env-0.6.2.tar.gz (1.7 kB)\n",
            "  Preparing metadata (setup.py) ... \u001b[?25l\u001b[?25hdone\n",
            "Requirement already satisfied: setuptools in /usr/local/lib/python3.10/dist-packages (from nodeenv>=0.11.1->pre-commit==2.20.0->-r requirements.txt (line 6)) (67.7.2)\n",
            "Collecting distlib<1,>=0.3.7 (from virtualenv>=20.0.8->pre-commit==2.20.0->-r requirements.txt (line 6))\n",
            "  Downloading distlib-0.3.8-py2.py3-none-any.whl (468 kB)\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m468.9/468.9 kB\u001b[0m \u001b[31m55.9 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hRequirement already satisfied: filelock<4,>=3.12.2 in /usr/local/lib/python3.10/dist-packages (from virtualenv>=20.0.8->pre-commit==2.20.0->-r requirements.txt (line 6)) (3.13.1)\n",
            "Requirement already satisfied: platformdirs<5,>=3.9.1 in /usr/local/lib/python3.10/dist-packages (from virtualenv>=20.0.8->pre-commit==2.20.0->-r requirements.txt (line 6)) (4.1.0)\n",
            "Building wheels for collected packages: pytest-env\n",
            "  Building wheel for pytest-env (setup.py) ... \u001b[?25l\u001b[?25hdone\n",
            "  Created wheel for pytest-env: filename=pytest_env-0.6.2-py3-none-any.whl size=2344 sha256=e927ee1c069ad470c5f47aa662500897cabe17eff6366d3fa8ec68e72f25775a\n",
            "  Stored in directory: /root/.cache/pip/wheels/62/dc/5a/862133b6d4688cfc367733985063f559f3b37ba99e62098458\n",
            "Successfully built pytest-env\n",
            "Installing collected packages: distlib, virtualenv, pytest-runner, py, nodeenv, mypy-extensions, identify, hypothesis, colorama, cfgv, pytest, pre-commit, mypy, pytest-env\n",
            "  Attempting uninstall: pytest\n",
            "    Found existing installation: pytest 7.4.4\n",
            "    Uninstalling pytest-7.4.4:\n",
            "      Successfully uninstalled pytest-7.4.4\n",
            "Successfully installed cfgv-3.4.0 colorama-0.4.3 distlib-0.3.8 hypothesis-6.54.0 identify-2.5.33 mypy-0.971 mypy-extensions-1.0.0 nodeenv-1.8.0 pre-commit-2.20.0 py-1.11.0 pytest-7.1.2 pytest-env-0.6.2 pytest-runner-5.2 virtualenv-20.25.0\n"
          ]
        }
      ],
      "source": [
        "!pip install -r requirements.txt"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 3,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "KB5PVywaJgpS",
        "outputId": "0df2b4e9-0e6f-4b70-e231-3f14efc44417"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Collecting datasets==2.4.0 (from -r requirements.extra.txt (line 1))\n",
            "  Downloading datasets-2.4.0-py3-none-any.whl (365 kB)\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m365.7/365.7 kB\u001b[0m \u001b[31m6.7 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hCollecting embeddings==0.0.8 (from -r requirements.extra.txt (line 2))\n",
            "  Downloading embeddings-0.0.8-py3-none-any.whl (12 kB)\n",
            "Collecting networkx==2.4 (from -r requirements.extra.txt (line 3))\n",
            "  Downloading networkx-2.4-py3-none-any.whl (1.6 MB)\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m1.6/1.6 MB\u001b[0m \u001b[31m58.6 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hCollecting plotly==4.14.3 (from -r requirements.extra.txt (line 4))\n",
            "  Downloading plotly-4.14.3-py2.py3-none-any.whl (13.2 MB)\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m13.2/13.2 MB\u001b[0m \u001b[31m63.6 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hCollecting pydot==1.4.1 (from -r requirements.extra.txt (line 5))\n",
            "  Downloading pydot-1.4.1-py2.py3-none-any.whl (19 kB)\n",
            "Collecting python-mnist (from -r requirements.extra.txt (line 6))\n",
            "  Downloading python_mnist-0.7-py2.py3-none-any.whl (9.6 kB)\n",
            "Collecting streamlit==1.12.0 (from -r requirements.extra.txt (line 7))\n",
            "  Downloading streamlit-1.12.0-py2.py3-none-any.whl (9.1 MB)\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m9.1/9.1 MB\u001b[0m \u001b[31m74.2 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hCollecting streamlit-ace (from -r requirements.extra.txt (line 8))\n",
            "  Downloading streamlit_ace-0.1.1-py3-none-any.whl (3.6 MB)\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m3.6/3.6 MB\u001b[0m \u001b[31m67.5 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hRequirement already satisfied: torch in /usr/local/lib/python3.10/dist-packages (from -r requirements.extra.txt (line 9)) (2.1.0+cu121)\n",
            "Collecting watchdog==1.0.2 (from -r requirements.extra.txt (line 10))\n",
            "  Downloading watchdog-1.0.2-py3-none-manylinux2014_x86_64.whl (72 kB)\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m72.6/72.6 kB\u001b[0m \u001b[31m11.5 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hRequirement already satisfied: numpy>=1.17 in /usr/local/lib/python3.10/dist-packages (from datasets==2.4.0->-r requirements.extra.txt (line 1)) (1.23.5)\n",
            "Requirement already satisfied: pyarrow>=6.0.0 in /usr/local/lib/python3.10/dist-packages (from datasets==2.4.0->-r requirements.extra.txt (line 1)) (10.0.1)\n",
            "Collecting dill<0.3.6 (from datasets==2.4.0->-r requirements.extra.txt (line 1))\n",
            "  Downloading dill-0.3.5.1-py2.py3-none-any.whl (95 kB)\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m95.8/95.8 kB\u001b[0m \u001b[31m17.1 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hRequirement already satisfied: pandas in /usr/local/lib/python3.10/dist-packages (from datasets==2.4.0->-r requirements.extra.txt (line 1)) (1.5.3)\n",
            "Requirement already satisfied: requests>=2.19.0 in /usr/local/lib/python3.10/dist-packages (from datasets==2.4.0->-r requirements.extra.txt (line 1)) (2.31.0)\n",
            "Requirement already satisfied: tqdm>=4.62.1 in /usr/local/lib/python3.10/dist-packages (from datasets==2.4.0->-r requirements.extra.txt (line 1)) (4.66.1)\n",
            "Requirement already satisfied: xxhash in /usr/local/lib/python3.10/dist-packages (from datasets==2.4.0->-r requirements.extra.txt (line 1)) (3.4.1)\n",
            "Collecting multiprocess (from datasets==2.4.0->-r requirements.extra.txt (line 1))\n",
            "  Downloading multiprocess-0.70.16-py310-none-any.whl (134 kB)\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m134.8/134.8 kB\u001b[0m \u001b[31m21.0 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hRequirement already satisfied: fsspec[http]>=2021.11.1 in /usr/local/lib/python3.10/dist-packages (from datasets==2.4.0->-r requirements.extra.txt (line 1)) (2023.6.0)\n",
            "Requirement already satisfied: aiohttp in /usr/local/lib/python3.10/dist-packages (from datasets==2.4.0->-r requirements.extra.txt (line 1)) (3.9.1)\n",
            "Requirement already satisfied: huggingface-hub<1.0.0,>=0.1.0 in /usr/local/lib/python3.10/dist-packages (from datasets==2.4.0->-r requirements.extra.txt (line 1)) (0.20.3)\n",
            "Requirement already satisfied: packaging in /usr/local/lib/python3.10/dist-packages (from datasets==2.4.0->-r requirements.extra.txt (line 1)) (23.2)\n",
            "Collecting responses<0.19 (from datasets==2.4.0->-r requirements.extra.txt (line 1))\n",
            "  Downloading responses-0.18.0-py3-none-any.whl (38 kB)\n",
            "Requirement already satisfied: decorator>=4.3.0 in /usr/local/lib/python3.10/dist-packages (from networkx==2.4->-r requirements.extra.txt (line 3)) (4.4.2)\n",
            "Collecting retrying>=1.3.3 (from plotly==4.14.3->-r requirements.extra.txt (line 4))\n",
            "  Downloading retrying-1.3.4-py3-none-any.whl (11 kB)\n",
            "Requirement already satisfied: six in /usr/local/lib/python3.10/dist-packages (from plotly==4.14.3->-r requirements.extra.txt (line 4)) (1.16.0)\n",
            "Requirement already satisfied: pyparsing>=2.1.4 in /usr/local/lib/python3.10/dist-packages (from pydot==1.4.1->-r requirements.extra.txt (line 5)) (3.1.1)\n",
            "Requirement already satisfied: altair>=3.2.0 in /usr/local/lib/python3.10/dist-packages (from streamlit==1.12.0->-r requirements.extra.txt (line 7)) (4.2.2)\n",
            "Requirement already satisfied: blinker>=1.0.0 in /usr/lib/python3/dist-packages (from streamlit==1.12.0->-r requirements.extra.txt (line 7)) (1.4)\n",
            "Requirement already satisfied: cachetools>=4.0 in /usr/local/lib/python3.10/dist-packages (from streamlit==1.12.0->-r requirements.extra.txt (line 7)) (5.3.2)\n",
            "Requirement already satisfied: click>=7.0 in /usr/local/lib/python3.10/dist-packages (from streamlit==1.12.0->-r requirements.extra.txt (line 7)) (8.1.7)\n",
            "Requirement already satisfied: importlib-metadata>=1.4 in /usr/local/lib/python3.10/dist-packages (from streamlit==1.12.0->-r requirements.extra.txt (line 7)) (7.0.1)\n",
            "Requirement already satisfied: pillow>=6.2.0 in /usr/local/lib/python3.10/dist-packages (from streamlit==1.12.0->-r requirements.extra.txt (line 7)) (9.4.0)\n",
            "Requirement already satisfied: protobuf<4,>=3.12 in /usr/local/lib/python3.10/dist-packages (from streamlit==1.12.0->-r requirements.extra.txt (line 7)) (3.20.3)\n",
            "Collecting pydeck>=0.1.dev5 (from streamlit==1.12.0->-r requirements.extra.txt (line 7))\n",
            "  Downloading pydeck-0.8.1b0-py2.py3-none-any.whl (4.8 MB)\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m4.8/4.8 MB\u001b[0m \u001b[31m121.7 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hCollecting pympler>=0.9 (from streamlit==1.12.0->-r requirements.extra.txt (line 7))\n",
            "  Downloading Pympler-1.0.1-py3-none-any.whl (164 kB)\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m164.8/164.8 kB\u001b[0m \u001b[31m27.1 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hRequirement already satisfied: python-dateutil in /usr/local/lib/python3.10/dist-packages (from streamlit==1.12.0->-r requirements.extra.txt (line 7)) (2.8.2)\n",
            "Requirement already satisfied: rich>=10.11.0 in /usr/local/lib/python3.10/dist-packages (from streamlit==1.12.0->-r requirements.extra.txt (line 7)) (13.7.0)\n",
            "Collecting semver (from streamlit==1.12.0->-r requirements.extra.txt (line 7))\n",
            "  Downloading semver-3.0.2-py3-none-any.whl (17 kB)\n",
            "Requirement already satisfied: toml in /usr/local/lib/python3.10/dist-packages (from streamlit==1.12.0->-r requirements.extra.txt (line 7)) (0.10.2)\n",
            "Requirement already satisfied: tornado>=5.0 in /usr/local/lib/python3.10/dist-packages (from streamlit==1.12.0->-r requirements.extra.txt (line 7)) (6.3.2)\n",
            "Requirement already satisfied: typing-extensions>=3.10.0.0 in /usr/local/lib/python3.10/dist-packages (from streamlit==1.12.0->-r requirements.extra.txt (line 7)) (4.5.0)\n",
            "Requirement already satisfied: tzlocal>=1.1 in /usr/local/lib/python3.10/dist-packages (from streamlit==1.12.0->-r requirements.extra.txt (line 7)) (5.2)\n",
            "Collecting validators>=0.2 (from streamlit==1.12.0->-r requirements.extra.txt (line 7))\n",
            "  Downloading validators-0.22.0-py3-none-any.whl (26 kB)\n",
            "Collecting gitpython!=3.1.19 (from streamlit==1.12.0->-r requirements.extra.txt (line 7))\n",
            "  Downloading GitPython-3.1.41-py3-none-any.whl (196 kB)\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m196.4/196.4 kB\u001b[0m \u001b[31m30.6 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hRequirement already satisfied: filelock in /usr/local/lib/python3.10/dist-packages (from torch->-r requirements.extra.txt (line 9)) (3.13.1)\n",
            "Requirement already satisfied: sympy in /usr/local/lib/python3.10/dist-packages (from torch->-r requirements.extra.txt (line 9)) (1.12)\n",
            "Requirement already satisfied: jinja2 in /usr/local/lib/python3.10/dist-packages (from torch->-r requirements.extra.txt (line 9)) (3.1.3)\n",
            "Requirement already satisfied: triton==2.1.0 in /usr/local/lib/python3.10/dist-packages (from torch->-r requirements.extra.txt (line 9)) (2.1.0)\n",
            "Requirement already satisfied: entrypoints in /usr/local/lib/python3.10/dist-packages (from altair>=3.2.0->streamlit==1.12.0->-r requirements.extra.txt (line 7)) (0.4)\n",
            "Requirement already satisfied: jsonschema>=3.0 in /usr/local/lib/python3.10/dist-packages (from altair>=3.2.0->streamlit==1.12.0->-r requirements.extra.txt (line 7)) (4.19.2)\n",
            "Requirement already satisfied: toolz in /usr/local/lib/python3.10/dist-packages (from altair>=3.2.0->streamlit==1.12.0->-r requirements.extra.txt (line 7)) (0.12.0)\n",
            "Requirement already satisfied: attrs>=17.3.0 in /usr/local/lib/python3.10/dist-packages (from aiohttp->datasets==2.4.0->-r requirements.extra.txt (line 1)) (23.2.0)\n",
            "Requirement already satisfied: multidict<7.0,>=4.5 in /usr/local/lib/python3.10/dist-packages (from aiohttp->datasets==2.4.0->-r requirements.extra.txt (line 1)) (6.0.4)\n",
            "Requirement already satisfied: yarl<2.0,>=1.0 in /usr/local/lib/python3.10/dist-packages (from aiohttp->datasets==2.4.0->-r requirements.extra.txt (line 1)) (1.9.4)\n",
            "Requirement already satisfied: frozenlist>=1.1.1 in /usr/local/lib/python3.10/dist-packages (from aiohttp->datasets==2.4.0->-r requirements.extra.txt (line 1)) (1.4.1)\n",
            "Requirement already satisfied: aiosignal>=1.1.2 in /usr/local/lib/python3.10/dist-packages (from aiohttp->datasets==2.4.0->-r requirements.extra.txt (line 1)) (1.3.1)\n",
            "Requirement already satisfied: async-timeout<5.0,>=4.0 in /usr/local/lib/python3.10/dist-packages (from aiohttp->datasets==2.4.0->-r requirements.extra.txt (line 1)) (4.0.3)\n",
            "Collecting gitdb<5,>=4.0.1 (from gitpython!=3.1.19->streamlit==1.12.0->-r requirements.extra.txt (line 7))\n",
            "  Downloading gitdb-4.0.11-py3-none-any.whl (62 kB)\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m62.7/62.7 kB\u001b[0m \u001b[31m11.5 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hRequirement already satisfied: pyyaml>=5.1 in /usr/local/lib/python3.10/dist-packages (from huggingface-hub<1.0.0,>=0.1.0->datasets==2.4.0->-r requirements.extra.txt (line 1)) (6.0.1)\n",
            "Requirement already satisfied: zipp>=0.5 in /usr/local/lib/python3.10/dist-packages (from importlib-metadata>=1.4->streamlit==1.12.0->-r requirements.extra.txt (line 7)) (3.17.0)\n",
            "Requirement already satisfied: pytz>=2020.1 in /usr/local/lib/python3.10/dist-packages (from pandas->datasets==2.4.0->-r requirements.extra.txt (line 1)) (2023.3.post1)\n",
            "Requirement already satisfied: MarkupSafe>=2.0 in /usr/local/lib/python3.10/dist-packages (from jinja2->torch->-r requirements.extra.txt (line 9)) (2.1.4)\n",
            "Requirement already satisfied: charset-normalizer<4,>=2 in /usr/local/lib/python3.10/dist-packages (from requests>=2.19.0->datasets==2.4.0->-r requirements.extra.txt (line 1)) (3.3.2)\n",
            "Requirement already satisfied: idna<4,>=2.5 in /usr/local/lib/python3.10/dist-packages (from requests>=2.19.0->datasets==2.4.0->-r requirements.extra.txt (line 1)) (3.6)\n",
            "Requirement already satisfied: urllib3<3,>=1.21.1 in /usr/local/lib/python3.10/dist-packages (from requests>=2.19.0->datasets==2.4.0->-r requirements.extra.txt (line 1)) (2.0.7)\n",
            "Requirement already satisfied: certifi>=2017.4.17 in /usr/local/lib/python3.10/dist-packages (from requests>=2.19.0->datasets==2.4.0->-r requirements.extra.txt (line 1)) (2023.11.17)\n",
            "Requirement already satisfied: markdown-it-py>=2.2.0 in /usr/local/lib/python3.10/dist-packages (from rich>=10.11.0->streamlit==1.12.0->-r requirements.extra.txt (line 7)) (3.0.0)\n",
            "Requirement already satisfied: pygments<3.0.0,>=2.13.0 in /usr/local/lib/python3.10/dist-packages (from rich>=10.11.0->streamlit==1.12.0->-r requirements.extra.txt (line 7)) (2.16.1)\n",
            "INFO: pip is looking at multiple versions of multiprocess to determine which version is compatible with other requirements. This could take a while.\n",
            "Collecting multiprocess (from datasets==2.4.0->-r requirements.extra.txt (line 1))\n",
            "  Downloading multiprocess-0.70.15-py310-none-any.whl (134 kB)\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m134.8/134.8 kB\u001b[0m \u001b[31m14.5 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25h  Downloading multiprocess-0.70.14-py310-none-any.whl (134 kB)\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m134.3/134.3 kB\u001b[0m \u001b[31m19.7 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25h  Downloading multiprocess-0.70.13-py310-none-any.whl (133 kB)\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m133.1/133.1 kB\u001b[0m \u001b[31m20.0 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hRequirement already satisfied: mpmath>=0.19 in /usr/local/lib/python3.10/dist-packages (from sympy->torch->-r requirements.extra.txt (line 9)) (1.3.0)\n",
            "Collecting smmap<6,>=3.0.1 (from gitdb<5,>=4.0.1->gitpython!=3.1.19->streamlit==1.12.0->-r requirements.extra.txt (line 7))\n",
            "  Downloading smmap-5.0.1-py3-none-any.whl (24 kB)\n",
            "Requirement already satisfied: jsonschema-specifications>=2023.03.6 in /usr/local/lib/python3.10/dist-packages (from jsonschema>=3.0->altair>=3.2.0->streamlit==1.12.0->-r requirements.extra.txt (line 7)) (2023.12.1)\n",
            "Requirement already satisfied: referencing>=0.28.4 in /usr/local/lib/python3.10/dist-packages (from jsonschema>=3.0->altair>=3.2.0->streamlit==1.12.0->-r requirements.extra.txt (line 7)) (0.32.1)\n",
            "Requirement already satisfied: rpds-py>=0.7.1 in /usr/local/lib/python3.10/dist-packages (from jsonschema>=3.0->altair>=3.2.0->streamlit==1.12.0->-r requirements.extra.txt (line 7)) (0.17.1)\n",
            "Requirement already satisfied: mdurl~=0.1 in /usr/local/lib/python3.10/dist-packages (from markdown-it-py>=2.2.0->rich>=10.11.0->streamlit==1.12.0->-r requirements.extra.txt (line 7)) (0.1.2)\n",
            "Installing collected packages: python-mnist, watchdog, validators, smmap, semver, retrying, pympler, pydot, networkx, dill, responses, pydeck, plotly, multiprocess, gitdb, embeddings, gitpython, datasets, streamlit, streamlit-ace\n",
            "  Attempting uninstall: pydot\n",
            "    Found existing installation: pydot 1.4.2\n",
            "    Uninstalling pydot-1.4.2:\n",
            "      Successfully uninstalled pydot-1.4.2\n",
            "  Attempting uninstall: networkx\n",
            "    Found existing installation: networkx 3.2.1\n",
            "    Uninstalling networkx-3.2.1:\n",
            "      Successfully uninstalled networkx-3.2.1\n",
            "  Attempting uninstall: plotly\n",
            "    Found existing installation: plotly 5.15.0\n",
            "    Uninstalling plotly-5.15.0:\n",
            "      Successfully uninstalled plotly-5.15.0\n",
            "\u001b[31mERROR: pip's dependency resolver does not currently take into account all the packages that are installed. This behaviour is the source of the following dependency conflicts.\n",
            "lida 0.0.10 requires fastapi, which is not installed.\n",
            "lida 0.0.10 requires kaleido, which is not installed.\n",
            "lida 0.0.10 requires python-multipart, which is not installed.\n",
            "lida 0.0.10 requires uvicorn, which is not installed.\u001b[0m\u001b[31m\n",
            "\u001b[0mSuccessfully installed datasets-2.4.0 dill-0.3.5.1 embeddings-0.0.8 gitdb-4.0.11 gitpython-3.1.41 multiprocess-0.70.13 networkx-2.4 plotly-4.14.3 pydeck-0.8.1b0 pydot-1.4.1 pympler-1.0.1 python-mnist-0.7 responses-0.18.0 retrying-1.3.4 semver-3.0.2 smmap-5.0.1 streamlit-1.12.0 streamlit-ace-0.1.1 validators-0.22.0 watchdog-1.0.2\n"
          ]
        }
      ],
      "source": [
        "!pip install -r requirements.extra.txt"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 4,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "LIF9pXvKKLPF",
        "outputId": "ab401e03-f75e-42e0-a926-89ee6268c8cc"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Obtaining file:///content/drive/MyDrive/11868/llmsys_code_examples/tensor_demo/miniTorch\n",
            "  Preparing metadata (setup.py) ... \u001b[?25l\u001b[?25hdone\n",
            "Installing collected packages: minitorch\n",
            "  Running setup.py develop for minitorch\n",
            "Successfully installed minitorch-0.4\n"
          ]
        }
      ],
      "source": [
        "!pip install -Ue ."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 5,
      "metadata": {
        "id": "TxA8MeBIhCI9",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "ae86abb0-47d2-4e54-f156-123b8c891f6e"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "bash: compile_cuda.sh: No such file or directory\n"
          ]
        }
      ],
      "source": [
        "!bash compile_cuda.sh"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 6,
      "metadata": {
        "id": "15_DC_j_KVWI"
      },
      "outputs": [],
      "source": [
        "import minitorch"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "0inD-mEqKwgv"
      },
      "source": [
        "## Go Through Minitorch\n",
        "\n",
        "This is a high level abstraction of some basic components in MiniTorch.\n",
        "\n",
        "<img src=\"./imgs/high_level_abstraction.png\"></img>"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "_Vmds3l9Kwgv"
      },
      "source": [
        "`class Parameter` is a very important component defined in `class Module`. What the models are learing is actually these `Parameter`(s). Optimizers also look for these parameters and update them following the weight updating rules. See `minitorch/module.py`."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "9ics4O5_Kwgw"
      },
      "outputs": [],
      "source": [
        "class Parameter:\n",
        "    \"\"\"\n",
        "    A Parameter is a special container stored in a `Module`.\n",
        "\n",
        "    It is designed to hold a `Variable`, but we allow it to hold\n",
        "    any value for testing.\n",
        "    \"\"\"\n",
        "\n",
        "    def __init__(self, x: Any, name: Optional[str] = None) -> None:\n",
        "        self.value = x\n",
        "        self.name = name\n",
        "        if hasattr(x, \"requires_grad_\"):\n",
        "            self.value.requires_grad_(True)\n",
        "            if self.name:\n",
        "                self.value.name = self.name\n",
        "\n",
        "    def update(self, x: Any) -> None:\n",
        "        \"Update the parameter value.\""
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "4WS47_bfKwgw"
      },
      "outputs": [],
      "source": [
        "class Module:\n",
        "    \"\"\"\n",
        "    Modules form a tree that store parameters and other\n",
        "    submodules. They make up the basis of neural network stacks.\n",
        "\n",
        "    Attributes:\n",
        "        _modules : Storage of the child modules\n",
        "        _parameters : Storage of the module's parameters\n",
        "        training : Whether the module is in training mode or evaluation mode\n",
        "\n",
        "    \"\"\"\n",
        "\n",
        "    _modules: Dict[str, Module]\n",
        "    _parameters: Dict[str, Parameter]\n",
        "    training: bool\n",
        "\n",
        "    def parameters(self) -> Sequence[Parameter]:\n",
        "        \"Enumerate over all the parameters of this module and its descendents.\"\n",
        "        return [j for _, j in self.named_parameters()]\n",
        "\n",
        "    def __call__(self, *args: Any, **kwargs: Any) -> Any:\n",
        "        return self.forward(*args, **kwargs)\n",
        "\n",
        "    def train(self) -> None:\n",
        "        \"Set the mode of this module and all descendent modules to `train`.\"\n",
        "        for m in self.modules():\n",
        "            m.train()\n",
        "        self.training = True\n",
        "\n",
        "    def eval(self) -> None:\n",
        "        \"Set the mode of this module and all descendent modules to `eval`.\"\n",
        "        for m in self.modules():\n",
        "            m.eval()\n",
        "        self.training = False"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "d-F0cQT5Kwgx"
      },
      "source": [
        "We define a `RParam` function here to initialize the `Parameter` in `project/run_sentiment.py`. We can define more functions for initialization i.e. [xavier](https://paperswithcode.com/method/xavier-initialization), [kaiming](https://paperswithcode.com/method/he-initialization) and structure them better inside the minitorch."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "8aJUrMzJKwgx"
      },
      "outputs": [],
      "source": [
        "# Initialization\n",
        "def RParam(*shape):\n",
        "    r = 0.1 * (minitorch.rand(shape, backend=BACKEND) - 0.5)\n",
        "    return minitorch.Parameter(r)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "wXU-yNXHKwgx"
      },
      "source": [
        "See `minitorch/optim.py`."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "5WWvsBvlKwgx"
      },
      "outputs": [],
      "source": [
        "class Optimizer:\n",
        "    def __init__(self, parameters: Sequence[Parameter]):\n",
        "        self.parameters = parameters\n",
        "\n",
        "\n",
        "class SGD(Optimizer):\n",
        "    def __init__(self, parameters: Sequence[Parameter], lr: float = 1.0):\n",
        "        super().__init__(parameters)\n",
        "        self.lr = lr\n",
        "\n",
        "    def step(self) -> None:\n",
        "        for p in self.parameters:\n",
        "            if p.value is None:\n",
        "                continue\n",
        "            elif hasattr(p.value, \"grad\"):\n",
        "                if p.value.grad is not None:\n",
        "                    p.update(p.value - self.lr * p.value.grad)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "LY_2R1vpKwgy"
      },
      "source": [
        "`class Function` is an abstraction for operators with `forward` and `backward` functions. It represents the kind of computation we perform at each node. See `minitorch/tensor_functions.py`."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "Dml5S37PKwgy"
      },
      "outputs": [],
      "source": [
        "class Function:\n",
        "    @classmethod\n",
        "    def _backward(cls, ctx: Context, grad_out: Tensor) -> Tuple[Tensor, ...]:\n",
        "        return wrap_tuple(cls.backward(ctx, grad_out))  # type: ignore\n",
        "\n",
        "    @classmethod\n",
        "    def _forward(cls, ctx: Context, *inps: Tensor) -> Tensor:\n",
        "        return cls.forward(ctx, *inps)  # type: ignore\n",
        "\n",
        "    @classmethod\n",
        "    def apply(cls, *vals: Tensor) -> Tensor:\n",
        "        raw_vals = []\n",
        "        need_grad = False\n",
        "        for v in vals:\n",
        "            if v.requires_grad():\n",
        "                need_grad = True\n",
        "            raw_vals.append(v.detach())\n",
        "\n",
        "        # Create the context.\n",
        "        ctx = Context(not need_grad)\n",
        "\n",
        "        # Call forward with the variables.\n",
        "        c = cls._forward(ctx, *raw_vals)\n",
        "\n",
        "        # Create a new variable from the result with a new history.\n",
        "        back = None\n",
        "        if need_grad:\n",
        "            back = minitorch.History(cls, ctx, vals)\n",
        "        return minitorch.Tensor(c._tensor, back, backend=c.backend)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "2qSIpDNBKwgy"
      },
      "outputs": [],
      "source": [
        "class Add(Function):\n",
        "    @staticmethod\n",
        "    def forward(ctx: Context, t1: Tensor, t2: Tensor) -> Tensor:\n",
        "        return t1.f.add_zip(t1, t2)\n",
        "\n",
        "    @staticmethod\n",
        "    def backward(ctx: Context, grad_output: Tensor) -> Tuple[Tensor, Tensor]:\n",
        "        return grad_output, grad_output"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "rnzUZd37Kwgz"
      },
      "source": [
        "`class Tensor` is the basic data structure that handles multidimensioanl arrays. See `minitorch/tensor.py`."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "lwcsCJiCKwgz"
      },
      "outputs": [],
      "source": [
        "class Tensor:\n",
        "    \"\"\"\n",
        "    Tensor is a generalization of Scalar in that it is a Variable that\n",
        "    handles multidimensional arrays.\n",
        "    \"\"\"\n",
        "\n",
        "    backend: TensorBackend\n",
        "    history: Optional[History]\n",
        "    grad: Optional[Tensor]\n",
        "    _tensor: TensorData\n",
        "    unique_id: int\n",
        "    name: str"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "cE8y70cPKwgz"
      },
      "source": [
        "## Data Storage and Operators\n",
        "\n",
        "This diagram shows several important components of `class Tensor`, including data storage `class TensorData`, backend `class TensorBackend`, etc. Backend relies on `class TensorOps` to execute the actual computation for different operators. Basic functions are implemented and abstracted by `class Function`.\n",
        "\n",
        "<img src=\"./imgs/data_storage_operators.png\"></img>"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "0ij11O6_Kwgz"
      },
      "outputs": [],
      "source": [
        "import numpy.typing as npt\n",
        "from typing import Sequence\n",
        "from typing_extensions import TypeAlias\n",
        "\n",
        "Storage: TypeAlias = npt.NDArray[np.float64]\n",
        "OutIndex: TypeAlias = npt.NDArray[np.int32]\n",
        "Index: TypeAlias = npt.NDArray[np.int32]\n",
        "Shape: TypeAlias = npt.NDArray[np.int32]\n",
        "Strides: TypeAlias = npt.NDArray[np.int32]\n",
        "\n",
        "UserIndex: TypeAlias = Sequence[int]\n",
        "UserShape: TypeAlias = Sequence[int]\n",
        "UserStrides: TypeAlias = Sequence[int]"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "D6AUI-1zKwg0"
      },
      "outputs": [],
      "source": [
        "class TensorData:\n",
        "    _storage: Storage\n",
        "    _strides: Strides\n",
        "    _shape: Shape\n",
        "    strides: UserStrides\n",
        "    shape: UserShape\n",
        "    dims: int"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "TOTAukDCKwg0"
      },
      "source": [
        "### Indexing\n",
        "\n",
        "<img src=\"./imgs/strides.png\"></img>"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 8,
      "metadata": {
        "id": "ARtLPu2wKwg1"
      },
      "outputs": [],
      "source": [
        "x = minitorch.tensor([1, 2, 3, 4, 5, 6])"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 9,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "UHzKqmt7Kwg1",
        "outputId": "1cca4682-29b8-4ff7-e317-9c2872afd763"
      },
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "array([1., 2., 3., 4., 5., 6.])"
            ]
          },
          "metadata": {},
          "execution_count": 9
        }
      ],
      "source": [
        "x.to_numpy()"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 10,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "_aflSF5cKwg1",
        "outputId": "1b6da46d-0a0a-4a2e-a1b5-15996eea1c78"
      },
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "((6,), (1,))"
            ]
          },
          "metadata": {},
          "execution_count": 10
        }
      ],
      "source": [
        "x._tensor.shape, x._tensor.strides"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 11,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "scBtjPIrKwg1",
        "outputId": "94f8c6d5-7b53-491b-f3b4-5a7e518d04d3"
      },
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "\n",
              "[\n",
              "\t[1.000000 2.000000 3.000000]\n",
              "\t[4.000000 5.000000 6.000000]]"
            ]
          },
          "metadata": {},
          "execution_count": 11
        }
      ],
      "source": [
        "y = minitorch.Tensor.make(\n",
        "    storage=x._tensor._storage,\n",
        "    shape=(2, 3),\n",
        "    strides=(3, 1),\n",
        "    backend=x.backend)\n",
        "y"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 12,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "5kj3abEVKwg1",
        "outputId": "ae4b99d7-415f-42ae-f999-3364edbfb881"
      },
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "array([1., 2., 3., 4., 5., 6.])"
            ]
          },
          "metadata": {},
          "execution_count": 12
        }
      ],
      "source": [
        "y._tensor._storage"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 13,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "eQEVHr4sKwg1",
        "outputId": "176a311f-0471-40c4-80a6-e8feb55cd379"
      },
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "True"
            ]
          },
          "metadata": {},
          "execution_count": 13
        }
      ],
      "source": [
        "y._tensor._storage is x._tensor._storage"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 14,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "37Ui7WoAKwg2",
        "outputId": "7f53b352-24a6-4643-8e34-fa8539913d6f"
      },
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "\n",
              "[\n",
              "\t[\n",
              "\t\t[1.000000]\n",
              "\t\t[2.000000]]\n",
              "\t[\n",
              "\t\t[3.000000]\n",
              "\t\t[4.000000]]\n",
              "\t[\n",
              "\t\t[5.000000]\n",
              "\t\t[6.000000]]]"
            ]
          },
          "metadata": {},
          "execution_count": 14
        }
      ],
      "source": [
        "z = x.view(3, 2, 1)\n",
        "z"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 15,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "En14LQscKwg2",
        "outputId": "a73a4c22-1612-44e0-81f7-67b904c97c4d"
      },
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "((3, 2, 1), (3, 1))"
            ]
          },
          "metadata": {},
          "execution_count": 15
        }
      ],
      "source": [
        "z._tensor.shape, y._tensor.strides"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 16,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "c4M4-YgfKwg2",
        "outputId": "efae768f-0f15-424a-a965-657e03b56dc4"
      },
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "True"
            ]
          },
          "metadata": {},
          "execution_count": 16
        }
      ],
      "source": [
        "z._tensor._storage is x._tensor._storage"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 17,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "7AR9aKBFKwg2",
        "outputId": "3f2d9de6-0722-46ee-b87d-c0a7b24c746c"
      },
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "(True, 3, 4.0)"
            ]
          },
          "metadata": {},
          "execution_count": 17
        }
      ],
      "source": [
        "z_index = [1, 1, 0]\n",
        "pos = minitorch.index_to_position(z_index, z._tensor._strides)\n",
        "z[tuple(z_index)] == z._tensor._storage[pos], pos, z[tuple(z_index)]"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 18,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "ljP7gomHKwg2",
        "outputId": "5db8dd16-3e10-451c-d8ac-30cc5f3088c0"
      },
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "[1, 1, 0]"
            ]
          },
          "metadata": {},
          "execution_count": 18
        }
      ],
      "source": [
        "out_index = [0, 0, 0]\n",
        "minitorch.to_index(3, z.shape, out_index)\n",
        "out_index"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 19,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "6UhJoSReKwg2",
        "outputId": "530815d9-924a-4822-ab61-1b1e884da60e"
      },
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "(3, 1)"
            ]
          },
          "metadata": {},
          "execution_count": 19
        }
      ],
      "source": [
        "shape = (2, 3)\n",
        "minitorch.strides_from_shape(shape)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 20,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "s1NGGsctKwg3",
        "outputId": "3ffde690-8ce8-4512-ed55-66d487d37c5d"
      },
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "(2, 1, 1)"
            ]
          },
          "metadata": {},
          "execution_count": 20
        }
      ],
      "source": [
        "shape = (3, 2, 1)\n",
        "minitorch.strides_from_shape(shape)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 21,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "5bCK6ZOVKwg3",
        "outputId": "87c4c129-6068-43c0-fdd7-3ce1f99dcadc"
      },
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "\n",
              "[\n",
              "\t[\n",
              "\t\t[1.000000 3.000000 5.000000]\n",
              "\t\t[2.000000 4.000000 6.000000]]]"
            ]
          },
          "metadata": {},
          "execution_count": 21
        }
      ],
      "source": [
        "p = z.permute(2, 1, 0)\n",
        "p"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 22,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "ZTYuZRGIKwg3",
        "outputId": "87e6f4a8-67d7-41c6-cf5c-f1787a7258fc"
      },
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "((1, 2, 3), (1, 1, 2))"
            ]
          },
          "metadata": {},
          "execution_count": 22
        }
      ],
      "source": [
        "p._tensor.shape, p._tensor.strides"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 23,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "Q28eHbRWKwg3",
        "outputId": "415bfbdd-b37c-44b4-ff33-61e37eb6fc2f"
      },
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "True"
            ]
          },
          "metadata": {},
          "execution_count": 23
        }
      ],
      "source": [
        "p._tensor._storage is x._tensor._storage"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 24,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "-UTlXzH2Kwg3",
        "outputId": "d22c355b-89a8-4d04-edef-aad98c8a3954"
      },
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "[0, 1, 2]"
            ]
          },
          "metadata": {},
          "execution_count": 24
        }
      ],
      "source": [
        "p_index = [0, 0, 0]\n",
        "minitorch.to_index(-1, p.shape, p_index)\n",
        "p_index"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 25,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "i2uQrsMLKwg3",
        "outputId": "58e09656-1177-4534-fb98-a4e64dcaea4b"
      },
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "5"
            ]
          },
          "metadata": {},
          "execution_count": 25
        }
      ],
      "source": [
        "minitorch.index_to_position(p_index, p._tensor._strides)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "ipScE_ULKwg4"
      },
      "source": [
        "### Backend & Operators\n",
        "\n",
        "See `minitorch/tensor_ops.py`"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "7QuP88fTKwg4"
      },
      "outputs": [],
      "source": [
        "class TensorOps:\n",
        "    @staticmethod\n",
        "    def map(fn: Callable[[float], float]) -> MapProto:\n",
        "        pass\n",
        "\n",
        "    @staticmethod\n",
        "    def zip(fn: Callable[[float, float], float]) -> Callable[[Tensor, Tensor], Tensor]:\n",
        "        pass\n",
        "\n",
        "    @staticmethod\n",
        "    def reduce(\n",
        "        fn: Callable[[float, float], float], start: float = 0.0\n",
        "    ) -> Callable[[Tensor, int], Tensor]:\n",
        "        pass\n",
        "\n",
        "    @staticmethod\n",
        "    def matrix_multiply(a: Tensor, b: Tensor) -> Tensor:\n",
        "        raise NotImplementedError(\"Not implemented in this assignment\")\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "Es03tJIBKwg4"
      },
      "outputs": [],
      "source": [
        "class TensorBackend:\n",
        "    def __init__(self, ops: Type[TensorOps]):\n",
        "        # Maps\n",
        "        self.neg_map = ops.map(operators.neg)\n",
        "        self.sigmoid_map = ops.map(operators.sigmoid)\n",
        "        self.relu_map = ops.map(operators.relu)\n",
        "        self.log_map = ops.map(operators.log)\n",
        "        self.exp_map = ops.map(operators.exp)\n",
        "        self.id_map = ops.map(operators.id)\n",
        "        self.id_cmap = ops.cmap(operators.id)\n",
        "        self.inv_map = ops.map(operators.inv)\n",
        "\n",
        "        # Zips\n",
        "        self.add_zip = ops.zip(operators.add)\n",
        "        self.mul_zip = ops.zip(operators.mul)\n",
        "        self.lt_zip = ops.zip(operators.lt)\n",
        "        self.eq_zip = ops.zip(operators.eq)\n",
        "        self.is_close_zip = ops.zip(operators.is_close)\n",
        "        self.relu_back_zip = ops.zip(operators.relu_back)\n",
        "        self.log_back_zip = ops.zip(operators.log_back)\n",
        "        self.inv_back_zip = ops.zip(operators.inv_back)\n",
        "\n",
        "        # Reduce\n",
        "        self.add_reduce = ops.reduce(operators.add, 0.0)\n",
        "        self.mul_reduce = ops.reduce(operators.mul, 1.0)\n",
        "\n",
        "        # Matrix Multiply\n",
        "        self.matrix_multiply = ops.matrix_multiply\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "F0KSoDe2Kwg4"
      },
      "outputs": [],
      "source": [
        "class CudaKernelOps(TensorOps):\n",
        "    @staticmethod\n",
        "    def map(fn: Callable[[float], float]) -> MapProto:\n",
        "        ### Your Implementation ###\n",
        "\n",
        "    @staticmethod\n",
        "    def zip(fn: Callable[[float, float], float]) -> Callable[[Tensor, Tensor], Tensor]:\n",
        "        ### Your Implementation ###\n",
        "\n",
        "    @staticmethod\n",
        "    def reduce(\n",
        "        fn: Callable[[float, float], float], start: float = 0.0\n",
        "    ) -> Callable[[Tensor, int], Tensor]:\n",
        "        ### Your Implementation ###\n",
        "\n",
        "    @staticmethod\n",
        "    def matrix_multiply(a: Tensor, b: Tensor) -> Tensor:\n",
        "        ### Your Implementation ###"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "uO7xsynCKwg4"
      },
      "outputs": [],
      "source": [
        "# In project/run_sentiment.py\n",
        "backend_name = \"CudaKernelOps\"\n",
        "\n",
        "if backend_name == \"CudaKernelOps\":\n",
        "    from minitorch.cuda_kernel_ops import CudaKernelOps\n",
        "    BACKEND = minitorch.TensorBackend(CudaKernelOps)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "fRqzdsHDKwg4"
      },
      "source": [
        "### Connect to CUDA Kernels"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "jPMj418zKwg4"
      },
      "outputs": [],
      "source": [
        "import ctypes\n",
        "import pycuda.gpuarray as gpuarray\n",
        "import pycuda.driver as drv\n",
        "from pycuda.compiler import SourceModule\n",
        "import pycuda.autoinit"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "nh7-UUUSKwg5"
      },
      "outputs": [],
      "source": [
        "try:\n",
        "    lib = ctypes.CDLL(\"minitorch/cuda_kernels/combine.so\")\n",
        "except:\n",
        "    print(\"cuda kernels not implemented: combine.so not found\")"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "b5wShSAxKwg5"
      },
      "outputs": [],
      "source": [
        "def map(fn: Callable[[float], float]) -> MapProto:\n",
        "    \"See `tensor_ops.py`\"\n",
        "    fn_id = fn_map[fn]\n",
        "\n",
        "    def ret(a: Tensor, out: Optional[Tensor] = None) -> Tensor:\n",
        "        if out is None:\n",
        "            out = a.zeros(a.shape)\n",
        "\n",
        "        # Define the argument type for the tensorMap function\n",
        "        lib.tensorMap.argtypes = [\n",
        "            ctypes.POINTER(ctypes.c_double),  # out\n",
        "            ctypes.POINTER(ctypes.c_int),    # out_shape\n",
        "            ctypes.POINTER(ctypes.c_int),    # out_strides\n",
        "            ctypes.c_int,                    # out_size\n",
        "            ctypes.POINTER(ctypes.c_double),  # in_storage\n",
        "            ctypes.POINTER(ctypes.c_int),    # in_shape\n",
        "            ctypes.POINTER(ctypes.c_int),    # in_strides\n",
        "            ctypes.c_int,                    # shape_len\n",
        "            ctypes.c_int,                    # fn_id\n",
        "        ]\n",
        "\n",
        "        # Define the return type for the tensorMap function\n",
        "        lib.tensorMap.restype = None\n",
        "\n",
        "        # Convert the numpy arrays to gpuarrays that can be loaded to the gpu\n",
        "        out_array_gpu = gpuarray.to_gpu(out._tensor._storage)\n",
        "        out_shape_gpu = gpuarray.to_gpu(out._tensor._shape.astype(np.int32))\n",
        "        out_strides_gpu = gpuarray.to_gpu(out._tensor._strides.astype(np.int32))\n",
        "        in_array_gpu = gpuarray.to_gpu(a._tensor._storage)\n",
        "        in_shape_gpu = gpuarray.to_gpu(a._tensor._shape.astype(np.int32))\n",
        "        in_strides_gpu = gpuarray.to_gpu(a._tensor._strides.astype(np.int32))\n",
        "\n",
        "\n",
        "        # Call the function\n",
        "        lib.tensorMap(\n",
        "            ctypes.cast(out_array_gpu.ptr, ctypes.POINTER(ctypes.c_double)),\n",
        "            ctypes.cast(out_shape_gpu.ptr, ctypes.POINTER(ctypes.c_int)),\n",
        "            ctypes.cast(out_strides_gpu.ptr, ctypes.POINTER(ctypes.c_int)),\n",
        "            ctypes.c_int(out.size),\n",
        "            ctypes.cast(in_array_gpu.ptr, ctypes.POINTER(ctypes.c_double)),\n",
        "            ctypes.cast(in_shape_gpu.ptr, ctypes.POINTER(ctypes.c_int)),\n",
        "            ctypes.cast(in_strides_gpu.ptr, ctypes.POINTER(ctypes.c_int)),\n",
        "            ctypes.c_int(len(a.shape)),\n",
        "            ctypes.c_int(fn_id)\n",
        "        )\n",
        "\n",
        "        # Copy the gpuarray back to the cpu\n",
        "        out._tensor._storage = out_array_gpu.get()\n",
        "\n",
        "        # Free the gpuarrays\n",
        "        out_array_gpu.gpudata.free()\n",
        "        out_shape_gpu.gpudata.free()\n",
        "        out_strides_gpu.gpudata.free()\n",
        "        in_array_gpu.gpudata.free()\n",
        "        in_shape_gpu.gpudata.free()\n",
        "        in_strides_gpu.gpudata.free()\n",
        "        return out\n",
        "\n",
        "    return ret"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "HU4Ahx1nKwg5"
      },
      "source": [
        "```c++\n",
        "    void tensorMap(\n",
        "        scalar_t* out,\n",
        "        int* out_shape,\n",
        "        int* out_strides,\n",
        "        int out_size,\n",
        "        scalar_t* in_storage,\n",
        "        int* in_shape,\n",
        "        int* in_strides,\n",
        "        int shape_size,\n",
        "        int fn_id\n",
        "    ) {\n",
        "        int threadsPerBlock = BASE_THREAD_NUM;\n",
        "        int blocksPerGrid = (out_size + threadsPerBlock - 1) / threadsPerBlock;\n",
        "        mapKernel<<<blocksPerGrid, threadsPerBlock>>>(out, out_shape, out_strides, out_size, in_storage, in_shape, in_strides, shape_size, fn_id);\n",
        "        cudaDeviceSynchronize();\n",
        "    }\n",
        "```"
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "## **MiniTorch Automatic Differentiation**"
      ],
      "metadata": {
        "id": "XOIi_tfGMbyn"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "from minitorch import SimpleBackend"
      ],
      "metadata": {
        "id": "ObLD2XlOMa-k"
      },
      "execution_count": 27,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "MiniTorch tensors are nodes in the computational graph as described in last lecture, just like how Pytorch tensors are nodes in the computational graph constructed in Pytorch.\n",
        "\n",
        "Note: this example uses SimpleBackend implemented in Python, which isn't nearly as good as your Cuda backend :)"
      ],
      "metadata": {
        "id": "NcLYzqnRMjQ1"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "Let's consider a simple example of $z = x * y$, the element-wise multiplication of two 1-d tensors.\n",
        "\n",
        "Suppose this happened somewhere in your Neural Network.\n",
        "\n",
        "During your backward pass, you've calculated your loss **$\\frac{\\partial loss}{\\partial z}$.**\n",
        "\n",
        "You want **$\\frac{\\partial loss}{\\partial x}$** and **$\\frac{\\partial loss}{\\partial y}$**"
      ],
      "metadata": {
        "id": "SyC8EG7DM2Rp"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "x = minitorch.tensor([1, 2, 3, 4, 5, 6], backend=SimpleBackend)"
      ],
      "metadata": {
        "id": "Xs5afN5MMpzO"
      },
      "execution_count": 28,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "x.requires_grad_(True)"
      ],
      "metadata": {
        "id": "Hw4_uu78Mrd7"
      },
      "execution_count": 29,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "x"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "_v0nxjHkMsZE",
        "outputId": "eb4817c1-b5c7-4a04-99ad-bb22addcd867"
      },
      "execution_count": 30,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "\n",
              "[1.000000 2.000000 3.000000 4.000000 5.000000 6.000000]"
            ]
          },
          "metadata": {},
          "execution_count": 30
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "y = minitorch.tensor([2, 4, 6, 8, 10, 12], backend=SimpleBackend)"
      ],
      "metadata": {
        "id": "KsxiG6qZMuLP"
      },
      "execution_count": 31,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "y.requires_grad_(True)"
      ],
      "metadata": {
        "id": "SLN44ySMMwhv"
      },
      "execution_count": 32,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "y"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "EGcml7r7MxYJ",
        "outputId": "34716c0b-0fc6-4617-fe22-8751575602e4"
      },
      "execution_count": 33,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "\n",
              "[2.000000 4.000000 6.000000 8.000000 10.000000 12.000000]"
            ]
          },
          "metadata": {},
          "execution_count": 33
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "z = x * y"
      ],
      "metadata": {
        "id": "MmGykxaHMyPK"
      },
      "execution_count": 34,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "z"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "64Qc8cpqMzHU",
        "outputId": "5811fe6a-f618-40b5-8906-ef9505ee2aca"
      },
      "execution_count": 35,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "\n",
              "[2.000000 8.000000 18.000000 32.000000 50.000000 72.000000]"
            ]
          },
          "metadata": {},
          "execution_count": 35
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "**How does MiniTorch calculate the gradients for each tensor?**\n",
        "\n",
        "By using *reverse mode automatic differentiation* - let's examine how this is implemented in MiniTorch with the simple example above of\n",
        "\n",
        "`z = x * y`"
      ],
      "metadata": {
        "id": "SDFHOyK-Nwnv"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "They contain important fields and methods for enabling automatic differentiation, including the\n",
        "* `self.f` field - tells us what backend we're using\n",
        "* `self.history` field - tracks the computation\n",
        "* `self.grad` field - stores the gradient for the optimizer\n",
        "* `chain_rule` method - lets us obtain partial adjoints for `backpropagate` to propagate from a node to its inputs\n",
        "\n"
      ],
      "metadata": {
        "id": "htY91cdMNz-P"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "We are going to utilize the computation graph as a way to automatically compute derivatives of arbitrary python functions.\n",
        "\n",
        "The trick behind this autodifferentiation is to implement the derivative of each individual function, and then utilize the chain rule to compute a derivative for any scale value."
      ],
      "metadata": {
        "id": "6RATsGxgN1z9"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "**Let's examine the trace of the forward evaluation**\n",
        "to get a better idea of how `z` got computed."
      ],
      "metadata": {
        "id": "tRd7dFTiN4vO"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "1. Open `minitorch/tensor.py:153` to find `__mul__`\n",
        "\n",
        "\n",
        "```python\n",
        "def __mul__(self, b: TensorLike) -> Tensor:\n",
        "        return Mul.apply(self, self._ensure_tensor(b))\n",
        "```\n",
        "\n"
      ],
      "metadata": {
        "id": "tvduw9OZN8Mz"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "2. Open `minitorch/tensor_functions.py:99` to find\n",
        "```python\n",
        "class Mul(Function):\n",
        "    @staticmethod\n",
        "    def forward(ctx: Context, a: Tensor, b: Tensor) -> Tensor:\n",
        "        ctx.save_for_backward(a, b)\n",
        "        return a.f.mul_zip(a, b)\n",
        "\n",
        "    @staticmethod\n",
        "    def backward(ctx: Context, grad_output: Tensor) -> Tuple[Tensor, Tensor]:\n",
        "        a, b = ctx.saved_values\n",
        "        return (\n",
        "            grad_output.f.mul_zip(b, grad_output),\n",
        "            grad_output.f.mul_zip(a, grad_output),\n",
        "        )\n",
        "```\n"
      ],
      "metadata": {
        "id": "E2oOIbMjN9cP"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "3. Open `minitorch/tensor_functions.py:33` to find\n",
        "\n",
        "```python\n",
        "class Function:\n",
        "    @classmethod\n",
        "    def _backward(cls, ctx: Context, grad_out: Tensor) -> Tuple[Tensor, ...]:\n",
        "        return wrap_tuple(cls.backward(ctx, grad_out))  # type: ignore\n",
        "\n",
        "    @classmethod\n",
        "    def _forward(cls, ctx: Context, *inps: Tensor) -> Tensor:\n",
        "        return cls.forward(ctx, *inps)  # type: ignore\n",
        "\n",
        "    @classmethod\n",
        "    def apply(cls, *vals: Tensor) -> Tensor:\n",
        "        raw_vals = []\n",
        "        need_grad = False\n",
        "        for v in vals:\n",
        "            if v.requires_grad():\n",
        "                need_grad = True\n",
        "            raw_vals.append(v.detach())\n",
        "\n",
        "        # Create the context.\n",
        "        ctx = Context(not need_grad)\n",
        "\n",
        "        # Call forward with the variables.\n",
        "        c = cls._forward(ctx, *raw_vals)\n",
        "        \n",
        "        back = None\n",
        "        if need_grad:\n",
        "            back = minitorch.History(cls, ctx, vals)\n",
        "        return minitorch.Tensor(c._tensor, back, backend=c.backend)\n",
        "```"
      ],
      "metadata": {
        "id": "aCVoaPFLN__y"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "\n",
        "So, we can see that Z is a new tensor with a **history**."
      ],
      "metadata": {
        "id": "caVkjSbrODs_"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "### **How do we get $\\frac{\\partial l}{\\partial x}$ and $\\frac{\\partial l}{\\partial y}$ given $\\frac{\\partial l}{\\partial z}$?**\n",
        "\n",
        "\n",
        "You've probably written this code in pytorch\n",
        "```python\n",
        "loss.sum().backward()\n",
        "```\n",
        "\n",
        "Since `loss.sum()` is still a tensor, you're calling the following method\n",
        "\n",
        "```python\n",
        "    def backward(self, grad_output: Optional[Tensor] = None) -> None:\n",
        "        if grad_output is None:\n",
        "            assert self.shape == (1,), \"Must provide grad_output if non-scalar\"\n",
        "            grad_output = Tensor.make([1.0], (1,), backend=self.backend)\n",
        "        backpropagate(self, grad_output)\n",
        "```\n"
      ],
      "metadata": {
        "id": "4xfBZ7PMOGC5"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "\n",
        "You've reached a point in the graph you've constructed for the backward pass where you have the following gradient propagated back to $z$"
      ],
      "metadata": {
        "id": "S78EcRTuOJl2"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "dldz = minitorch.tensor([1, 1, 1, 1, 1, 1], backend=SimpleBackend)"
      ],
      "metadata": {
        "id": "3XADUxquOJ0k"
      },
      "execution_count": 36,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "Let's make use of `z.history`, which tells us:\n",
        "1. The function used to calculate z\n",
        "2. The context ie. intermediate values we need to calculate the gradients of z's inputs"
      ],
      "metadata": {
        "id": "MNoqEQkjONVq"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "z.history"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "2Z54eaYtOL2s",
        "outputId": "b834c874-c465-410c-c913-0db0650821d3"
      },
      "execution_count": 37,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "History(last_fn=<class 'minitorch.tensor_functions.Mul'>, ctx=Context(no_grad=False, saved_values=(\n",
              "[1.000000 2.000000 3.000000 4.000000 5.000000 6.000000], \n",
              "[2.000000 4.000000 6.000000 8.000000 10.000000 12.000000])), inputs=(\n",
              "[1.000000 2.000000 3.000000 4.000000 5.000000 6.000000], \n",
              "[2.000000 4.000000 6.000000 8.000000 10.000000 12.000000]))"
            ]
          },
          "metadata": {},
          "execution_count": 37
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "In your `backpropagate` function, you should use the `chain_rule` method of a tensor in `minitorch/tensor.py:373`.\n",
        "\n",
        "```python\n",
        "    def chain_rule(self, d_output: Any) -> Iterable[Tuple[Variable, Any]]:\n",
        "        h = self.history\n",
        "        assert h is not None\n",
        "        assert h.last_fn is not None\n",
        "        assert h.ctx is not None\n",
        "\n",
        "        x = h.last_fn._backward(h.ctx, d_output)\n",
        "        assert len(x) == len(h.inputs), f\"Bug in function {h.last_fn}\"\n",
        "        return [\n",
        "            (inp, inp.expand(self._ensure_tensor(d_in)))\n",
        "            for inp, d_in in zip(h.inputs, x)\n",
        "        ]\n",
        "```\n"
      ],
      "metadata": {
        "id": "wr-cq8FNOQyy"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "z.history.last_fn"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "TiqjO9zdOPRi",
        "outputId": "18ddfb97-c4f8-4aa6-b87e-9c7ab83ca076"
      },
      "execution_count": 38,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "minitorch.tensor_functions.Mul"
            ]
          },
          "metadata": {},
          "execution_count": 38
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# saved_values == (x, y)\n",
        "z.history.ctx"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "HdPAjWIsOSaR",
        "outputId": "b62261fc-e1c5-4e91-9c57-072e511b9f0f"
      },
      "execution_count": 39,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "Context(no_grad=False, saved_values=(\n",
              "[1.000000 2.000000 3.000000 4.000000 5.000000 6.000000], \n",
              "[2.000000 4.000000 6.000000 8.000000 10.000000 12.000000]))"
            ]
          },
          "metadata": {},
          "execution_count": 39
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "If $z = x*y$ then $\\frac{\\partial l}{\\partial x} = \\frac{\\partial l}{\\partial z} \\frac{\\partial z}{\\partial x} = \\frac{\\partial l}{\\partial z} y$"
      ],
      "metadata": {
        "id": "aatjEeJxOYAX"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "\n",
        "Open `minitorch/tensor_functions.py:99` to find\n",
        "```python\n",
        "class Mul(Function):\n",
        "    @staticmethod\n",
        "    def forward(ctx: Context, a: Tensor, b: Tensor) -> Tensor:\n",
        "        ctx.save_for_backward(a, b)\n",
        "        return a.f.mul_zip(a, b)\n",
        "\n",
        "    @staticmethod\n",
        "    def backward(ctx: Context, grad_output: Tensor) -> Tuple[Tensor, Tensor]:\n",
        "        a, b = ctx.saved_values\n",
        "        return (\n",
        "            grad_output.f.mul_zip(b, grad_output),\n",
        "            grad_output.f.mul_zip(a, grad_output),\n",
        "        )\n",
        "```"
      ],
      "metadata": {
        "id": "1zk1ink0Owjy"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# This is exactly what's happening in backward!\n",
        "dldx, dldy = z.history.last_fn._backward(z.history.ctx, dldz)"
      ],
      "metadata": {
        "id": "53FFiHhqOTXt"
      },
      "execution_count": 45,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "$\\frac{\\partial l}{\\partial x} = \\frac{\\partial l}{\\partial z} \\frac{\\partial z}{\\partial x} = \\frac{\\partial l}{\\partial z} y$\n",
        "```python\n",
        "dldx = tensor([1,1,1,1,1,1]) * tensor([2,4,6,8,10,12])\n",
        "```"
      ],
      "metadata": {
        "id": "6sUs5ZZiOdyR"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "dldx # = dldz * y"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "7emxjBhSOUkt",
        "outputId": "6e792145-c03d-4b8a-f5a0-749c46856997"
      },
      "execution_count": 46,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "\n",
              "[2.000000 4.000000 6.000000 8.000000 10.000000 12.000000]"
            ]
          },
          "metadata": {},
          "execution_count": 46
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "(dldz * y) == dldx"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "XlpUEUqiOgXu",
        "outputId": "a1af23d1-a0b6-4b9e-aa7e-1031f648584d"
      },
      "execution_count": 42,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "\n",
              "[1.000000 1.000000 1.000000 1.000000 1.000000 1.000000]"
            ]
          },
          "metadata": {},
          "execution_count": 42
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "dldy # = dldz * x"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "z6vmnIzUOhV1",
        "outputId": "be570de1-c0f6-4b9d-800f-ab3f7f36cad1"
      },
      "execution_count": 43,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "\n",
              "[1.000000 2.000000 3.000000 4.000000 5.000000 6.000000]"
            ]
          },
          "metadata": {},
          "execution_count": 43
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "(dldz * x) == dldy"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "FvD4ddzIOiD9",
        "outputId": "5db21480-743c-401b-d0cf-81c3cefe7234"
      },
      "execution_count": 44,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "\n",
              "[1.000000 1.000000 1.000000 1.000000 1.000000 1.000000]"
            ]
          },
          "metadata": {},
          "execution_count": 44
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "Defining functions in this way (Tensor in, Tensor out) is really powerful because it enables us to easily calculate the gradient of any python function that operates on Tensors eg. .sum(), .permute(), etc.\n",
        "\n",
        "There are many things to be careful of when shapes change eg.\n",
        "How do you calculate the gradient when you've done a `.sum(dim=2)`?\n",
        "\n",
        "Backpropagation vs. Reverse Mode Automatic Differentiation\n",
        "1. Modern deep learning frameworks don't use backpropagation on the forward computational graph.\n"
      ],
      "metadata": {
        "id": "86o3hrUwOlT9"
      }
    }
  ],
  "metadata": {
    "accelerator": "GPU",
    "colab": {
      "collapsed_sections": [
        "IYJbDGLrIK93",
        "gH9OYx-XJNGQ",
        "mWRAVR1kQSFS",
        "QE0eesQ04d-W",
        "xSo94QvzCFbn",
        "7sejR8-MTPmM",
        "RdCXpyn3j9e-"
      ],
      "gpuType": "T4",
      "provenance": []
    },
    "kernelspec": {
      "display_name": "Python 3",
      "name": "python3"
    },
    "language_info": {
      "codemirror_mode": {
        "name": "ipython",
        "version": 3
      },
      "file_extension": ".py",
      "mimetype": "text/x-python",
      "name": "python",
      "nbconvert_exporter": "python",
      "pygments_lexer": "ipython3",
      "version": "3.8.18"
    }
  },
  "nbformat": 4,
  "nbformat_minor": 0
}