{
  "cells": [
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Drive already mounted at /content/drive; to attempt to forcibly remount, call drive.mount(\"/content/drive\", force_remount=True).\n",
            "/content/drive/MyDrive\n",
            "/content/drive/MyDrive/11868/test\n",
            "Cloning into 'code_examples'...\n",
            "remote: Enumerating objects: 17, done.\u001b[K\n",
            "remote: Counting objects: 100% (17/17), done.\u001b[K\n",
            "remote: Compressing objects: 100% (11/11), done.\u001b[K\n",
            "remote: Total 17 (delta 3), reused 17 (delta 3), pack-reused 0\u001b[K\n",
            "Receiving objects: 100% (17/17), 5.86 KiB | 750.00 KiB/s, done.\n",
            "Resolving deltas: 100% (3/3), done.\n",
            "/content/drive/MyDrive/11868/test/code_examples/cuda_demo\n"
          ]
        }
      ],
      "source": [
        "from google.colab import drive\n",
        "drive.mount('/content/drive')\n",
        "%cd /content/drive/MyDrive/\n",
        "!mkdir -p 11868\n",
        "%cd /content/drive/MyDrive/11868\n",
        "!git clone https://github.com/llmsystem/llmsys_code_examples.git\n",
        "%cd /content/drive/MyDrive/11868/llmsys_code_examples/cuda_demo"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Collecting pycuda\n",
            "  Downloading pycuda-2024.1.tar.gz (1.7 MB)\n",
            "\u001b[?25l     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m0.0/1.7 MB\u001b[0m \u001b[31m?\u001b[0m eta \u001b[36m-:--:--\u001b[0m\r\u001b[2K     \u001b[91m━━━\u001b[0m\u001b[90m╺\u001b[0m\u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m0.1/1.7 MB\u001b[0m \u001b[31m4.1 MB/s\u001b[0m eta \u001b[36m0:00:01\u001b[0m\r\u001b[2K     \u001b[91m━━━━━━━━━━━\u001b[0m\u001b[90m╺\u001b[0m\u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m0.5/1.7 MB\u001b[0m \u001b[31m6.8 MB/s\u001b[0m eta \u001b[36m0:00:01\u001b[0m\r\u001b[2K     \u001b[91m━━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[91m╸\u001b[0m\u001b[90m━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m0.9/1.7 MB\u001b[0m \u001b[31m8.8 MB/s\u001b[0m eta \u001b[36m0:00:01\u001b[0m\r\u001b[2K     \u001b[91m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[90m╺\u001b[0m\u001b[90m━━━━\u001b[0m \u001b[32m1.5/1.7 MB\u001b[0m \u001b[31m10.7 MB/s\u001b[0m eta \u001b[36m0:00:01\u001b[0m\r\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m1.7/1.7 MB\u001b[0m \u001b[31m10.4 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25h  Installing build dependencies ... \u001b[?25l\u001b[?25hdone\n",
            "  Getting requirements to build wheel ... \u001b[?25l\u001b[?25hdone\n",
            "  Preparing metadata (pyproject.toml) ... \u001b[?25l\u001b[?25hdone\n",
            "Collecting pytools>=2011.2 (from pycuda)\n",
            "  Downloading pytools-2023.1.1-py2.py3-none-any.whl (70 kB)\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m70.6/70.6 kB\u001b[0m \u001b[31m9.5 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hRequirement already satisfied: appdirs>=1.4.0 in /usr/local/lib/python3.10/dist-packages (from pycuda) (1.4.4)\n",
            "Collecting mako (from pycuda)\n",
            "  Downloading Mako-1.3.0-py3-none-any.whl (78 kB)\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m78.6/78.6 kB\u001b[0m \u001b[31m11.3 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hRequirement already satisfied: platformdirs>=2.2.0 in /usr/local/lib/python3.10/dist-packages (from pytools>=2011.2->pycuda) (4.1.0)\n",
            "Requirement already satisfied: typing-extensions>=4.0 in /usr/local/lib/python3.10/dist-packages (from pytools>=2011.2->pycuda) (4.5.0)\n",
            "Requirement already satisfied: MarkupSafe>=0.9.2 in /usr/local/lib/python3.10/dist-packages (from mako->pycuda) (2.1.3)\n",
            "Building wheels for collected packages: pycuda\n",
            "  Building wheel for pycuda (pyproject.toml) ... \u001b[?25l\u001b[?25hdone\n",
            "  Created wheel for pycuda: filename=pycuda-2024.1-cp310-cp310-linux_x86_64.whl size=661205 sha256=87b18480433e8cc46e8387b1463bb1b1fa14bd3c2f1dcf7f9a33451b88e59872\n",
            "  Stored in directory: /root/.cache/pip/wheels/12/34/d2/9a349255a4eca3a486d82c79d21e138ce2ccd90f414d9d72b8\n",
            "Successfully built pycuda\n",
            "Installing collected packages: pytools, mako, pycuda\n",
            "Successfully installed mako-1.3.0 pycuda-2024.1 pytools-2023.1.1\n"
          ]
        }
      ],
      "source": [
        "!pip install pycuda"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "## CUDA Example for Vector Add\n",
        "\n",
        "We demonstrate how we can call C function in python file with ctypes with `VecAddCPU` function.\n",
        "\n",
        "We also demonstrate two ways to write CUDA codes which can be called in python functions. The difference between them is that we create CUDA memory and copy the data to CUDA device by `pycuda` package in the `VecAddCUDA` function and `cudaMemcpy` in cpp codes in `VecAddCUDA2` function.\n",
        "\n",
        "We use `pycuda` in assignment1 to call CUDA kernel functions."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "!nvcc -o vector_add.so --shared example_vector_add.cu -Xcompiler -fPIC"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Input a: [7 5 1 7 6 4 7 3 9 3]\n",
            "Input b: [8 4 2 6 5 1 7 7 8 6]\n",
            "Numpy add: [15  9  3 13 11  5 14 10 17  9], <class 'numpy.ndarray'>\n",
            "CPU add: [15  9  3 13 11  5 14 10 17  9], <class 'numpy.ndarray'>\n",
            "GPU add: [15  9  3 13 11  5 14 10 17  9], <class 'pycuda.gpuarray.GPUArray'>\n",
            "After offload: [15  9  3 13 11  5 14 10 17  9], <class 'numpy.ndarray'>\n",
            "GPU add2: [15  9  3 13 11  5 14 10 17  9], <class 'numpy.ndarray'>\n"
          ]
        }
      ],
      "source": [
        "!python test_vector_add.py"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "## CUDA Example for Window Sum\n",
        "\n",
        "Demo of Window Sum to get to know synchronization in CUDA."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "!nvcc -o window_sum.so --shared example_window_sum.cu -Xcompiler -fPIC"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Input: [ 1.  2.  3.  4.  5.  6.  7.  8.  9. 10. 11. 12.]\n",
            "Numpy window sum: [15. 20. 25. 30. 35. 40. 45. 50.]\n",
            "GPU simple window sum: [15. 20. 25. 30. 35. 40. 45. 50.]\n",
            "GPU shared window sum: [15. 20. 25. 30. 35. 40. 45. 50.]\n"
          ]
        }
      ],
      "source": [
        "!python test_window_sum.py"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "## CUDA Example for Matrix Multiplication\n",
        "\n",
        "Demo of matrix multiplication."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "!nvcc -o matmul.so --shared example_matmul.cu -Xcompiler -fPIC"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Input a: [[1. 2. 2. 1.]\n",
            " [2. 2. 2. 2.]\n",
            " [2. 2. 2. 1.]\n",
            " [1. 2. 1. 1.]]\n",
            "Input b: [[1. 1.]\n",
            " [1. 2.]\n",
            " [1. 2.]\n",
            " [2. 1.]]\n",
            "Numpy matmul: [[ 7. 10.]\n",
            " [10. 12.]\n",
            " [ 8. 11.]\n",
            " [ 6.  8.]], <class 'numpy.ndarray'>\n",
            "GPU matmul: [[ 7. 10.]\n",
            " [10. 12.]\n",
            " [ 8. 11.]\n",
            " [ 6.  8.]], <class 'pycuda.gpuarray.GPUArray'>\n",
            "After offload: [[ 7. 10.]\n",
            " [10. 12.]\n",
            " [ 8. 11.]\n",
            " [ 6.  8.]], <class 'numpy.ndarray'>\n",
            "Compare result: 0.0\n"
          ]
        }
      ],
      "source": [
        "!python test_matmul.py"
      ]
    }
  ],
  "metadata": {
    "accelerator": "GPU",
    "colab": {
      "gpuType": "T4",
      "provenance": []
    },
    "kernelspec": {
      "display_name": "Python 3",
      "name": "python3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "nbformat": 4,
  "nbformat_minor": 0
}
