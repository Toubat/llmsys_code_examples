{
  "cells": [
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "bnwssnByS00Y",
        "outputId": "59c07f0d-5788-46e7-b473-330dc74d68c1"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Mounted at /content/drive\n",
            "/content/drive/MyDrive\n",
            "/content/drive/MyDrive/11868/cuda_version\n"
          ]
        }
      ],
      "source": [
        "from google.colab import drive\n",
        "drive.mount('/content/drive')\n",
        "%cd /content/drive/MyDrive/\n",
        "!mkdir -p 11868\n",
        "!git clone https://github.com/llmsystem/code_examples.git\n",
        "%cd /content/drive/MyDrive/11868/code_examples/cuda_demo"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "PhKFJ0VIXN8D",
        "outputId": "f5e896c4-5782-417d-fb43-a425d6eef5b7"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Requirement already satisfied: pycuda in /usr/local/lib/python3.10/dist-packages (2024.1)\n",
            "Requirement already satisfied: pytools>=2011.2 in /usr/local/lib/python3.10/dist-packages (from pycuda) (2023.1.1)\n",
            "Requirement already satisfied: appdirs>=1.4.0 in /usr/local/lib/python3.10/dist-packages (from pycuda) (1.4.4)\n",
            "Requirement already satisfied: mako in /usr/local/lib/python3.10/dist-packages (from pycuda) (1.3.0)\n",
            "Requirement already satisfied: platformdirs>=2.2.0 in /usr/local/lib/python3.10/dist-packages (from pytools>=2011.2->pycuda) (4.1.0)\n",
            "Requirement already satisfied: typing-extensions>=4.0 in /usr/local/lib/python3.10/dist-packages (from pytools>=2011.2->pycuda) (4.5.0)\n",
            "Requirement already satisfied: MarkupSafe>=0.9.2 in /usr/local/lib/python3.10/dist-packages (from mako->pycuda) (2.1.3)\n"
          ]
        }
      ],
      "source": [
        "!pip install pycuda"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "jU7sWLQ5XCnk"
      },
      "outputs": [],
      "source": [
        "!nvcc -o vector_add.so --shared example_vector_add.cu -Xcompiler -fPIC"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "bSk4XhB4fxoj",
        "outputId": "ae1f06c6-9633-40c9-fcff-99a932cb3f10"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Input a: [2 5 3 1 1 8 7 7 5 6]\n",
            "Input b: [2 1 9 5 1 7 6 1 7 4]\n",
            "Numpy add: [ 4  6 12  6  2 15 13  8 12 10], <class 'numpy.ndarray'>\n",
            "CPU add: [ 4  6 12  6  2 15 13  8 12 10], <class 'numpy.ndarray'>\n",
            "GPU add: [ 4  6 12  6  2 15 13  8 12 10], <class 'pycuda.gpuarray.GPUArray'>\n",
            "After offload: [ 4  6 12  6  2 15 13  8 12 10], <class 'numpy.ndarray'>\n",
            "GPU add2: [ 4  6 12  6  2 15 13  8 12 10], <class 'numpy.ndarray'>\n"
          ]
        }
      ],
      "source": [
        "!python test_vector_add.py"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 211,
      "metadata": {
        "id": "CkYzvgVapHi5"
      },
      "outputs": [],
      "source": [
        "!nvcc -o matmul.so --shared example_matmul.cu -Xcompiler -fPIC"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 212,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "ymHfmCJrrJYq",
        "outputId": "8307d1bd-f953-4f77-cd95-d1927c783601"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Input a: [[1. 2. 2. 1.]\n",
            " [2. 2. 2. 2.]\n",
            " [2. 2. 2. 1.]\n",
            " [1. 2. 1. 1.]]\n",
            "Input b: [[1. 1.]\n",
            " [1. 2.]\n",
            " [1. 2.]\n",
            " [2. 1.]]\n",
            "Numpy matmul: [[ 7. 10.]\n",
            " [10. 12.]\n",
            " [ 8. 11.]\n",
            " [ 6.  8.]], <class 'numpy.ndarray'>\n",
            "GPU matmul: [[ 7. 10.]\n",
            " [10. 12.]\n",
            " [ 8. 11.]\n",
            " [ 6.  8.]], <class 'pycuda.gpuarray.GPUArray'>\n",
            "After offload: [[ 7. 10.]\n",
            " [10. 12.]\n",
            " [ 8. 11.]\n",
            " [ 6.  8.]], <class 'numpy.ndarray'>\n",
            "Compare result: 0.0\n",
            "block[0, 0], thread[0, 0], a_shared: 1.000000\n",
            "block[0, 0], thread[1, 0], a_shared: 2.000000\n",
            "block[0, 0], thread[0, 1], a_shared: 2.000000\n",
            "block[0, 0], thread[1, 1], a_shared: 2.000000\n",
            "block[1, 0], thread[0, 0], a_shared: 2.000000\n",
            "block[1, 0], thread[1, 0], a_shared: 1.000000\n",
            "block[1, 0], thread[0, 1], a_shared: 2.000000\n",
            "block[1, 0], thread[1, 1], a_shared: 2.000000\n",
            "block[0, 0], thread[0, 0], b_shared: 1.000000\n",
            "block[0, 0], thread[1, 0], b_shared: 1.000000\n",
            "block[0, 0], thread[0, 1], b_shared: 1.000000\n",
            "block[0, 0], thread[1, 1], b_shared: 2.000000\n",
            "block[1, 0], thread[0, 0], b_shared: 1.000000\n",
            "block[1, 0], thread[1, 0], b_shared: 1.000000\n",
            "block[1, 0], thread[0, 1], b_shared: 1.000000\n",
            "block[1, 0], thread[1, 1], b_shared: 2.000000\n",
            "block[0, 0], thread[0, 0], accum: 3.000000\n",
            "block[0, 0], thread[1, 0], accum: 4.000000\n",
            "block[0, 0], thread[0, 1], accum: 5.000000\n",
            "block[0, 0], thread[1, 1], accum: 6.000000\n",
            "block[1, 0], thread[0, 0], accum: 4.000000\n",
            "block[1, 0], thread[1, 0], accum: 3.000000\n",
            "block[1, 0], thread[0, 1], accum: 6.000000\n",
            "block[1, 0], thread[1, 1], accum: 5.000000\n",
            "GPU matmul: [3. 5. 4. 6. 4. 6. 3. 5.], <class 'pycuda.gpuarray.GPUArray'>\n",
            "After offload: [3. 5. 4. 6. 4. 6. 3. 5.], <class 'numpy.ndarray'>\n",
            "GPU matmul: [ 7. 10. 10. 12.  8. 11.  6.  8.], <class 'pycuda.gpuarray.GPUArray'>\n",
            "After offload: [ 7. 10. 10. 12.  8. 11.  6.  8.], <class 'numpy.ndarray'>\n"
          ]
        }
      ],
      "source": [
        "!python test_matmul.py"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "ADrq4oYiyMs5"
      },
      "outputs": [],
      "source": [
        "!nvcc -o window_sum.so --shared example_window_sum.cu -Xcompiler -fPIC"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "GsU6-37HxFKO",
        "outputId": "83d4e7a8-1895-4aeb-b158-f5d04bed0d35"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Input: [ 1.  2.  3.  4.  5.  6.  7.  8.  9. 10. 11. 12.]\n",
            "Numpy window sum: [15. 20. 25. 30. 35. 40. 45. 50.]\n",
            "GPU simple window sum: [15. 20. 25. 30. 35. 40. 45. 50.]\n",
            "GPU shared window sum: [15. 20. 25. 30. 35. 40. 45. 50.]\n"
          ]
        }
      ],
      "source": [
        "!python test_window_sum.py"
      ]
    }
  ],
  "metadata": {
    "accelerator": "GPU",
    "colab": {
      "gpuType": "T4",
      "provenance": []
    },
    "kernelspec": {
      "display_name": "Python 3",
      "name": "python3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "nbformat": 4,
  "nbformat_minor": 0
}
